use super::EncodedProp;
use amethyst_assets::{Asset, Handle, ProcessingState, Result};
use amethyst_core::specs::{world::Index, VecStorage};
use hibitset::BitSet;
use std::cell::{Ref, RefCell};

/// A set of shader properties at specific offsets.
/// The type should guarantee that all properties are non-overlapping.
/// TODO: do the actual validation at creation time.
#[derive(PartialEq, Eq, Hash, Clone, Debug)]
pub struct EncodingLayout {
    /// A list of all properties at specific offset
    pub props: Vec<LayoutProp>,
    /// Total number of bytes required for the structure, including padding
    pub padded_size: u32,
}

pub struct EncodingLayout2 {
    buffers: Vec<EncodingBufferLayout>,
    attributes: Vec<EncodedProp>,
}

pub struct EncodingBufferLayout {
    /// A list of all properties at specific offset
    pub props: Vec<LayoutProp>,
    /// Total number of bytes required for the structure, including padding
    pub padded_size: u32,
}

impl EncodingLayout {
    /// Extract encoding layout from shader
    pub fn from_shader(shader: &Shader) -> Self {
        // TODO: cheating here, needs a real shader with proper
        // spirv-reflect data to implement that properly
        shader.mock_layout.clone()
    }
}

#[derive(PartialEq, Eq, Hash, Clone, Debug)]
pub struct LayoutProp {
    /// Name and type of the property. Determines the encoders to run.
    pub prop: EncodedProp,
    /// Offset in bytes fro mthe start of the layout structure.
    /// Instructs the `BufferWriter` where to put the encoded data.
    pub absolute_offset: u32,
}

impl LayoutProp {
    pub fn ubo_size(&self) -> usize {
        self.prop.0.ubo_size()
    }
}

/// Shader structure placeholder
/// TODO: use actual shaders
pub struct Shader {
    /// Temporary way to test against hardcoded layout
    pub mock_layout: EncodingLayout,
}

impl Asset for Shader {
    const NAME: &'static str = "Shader";
    type HandleStorage = VecStorage<Handle<Self>>;
    type Data = Self;
}
impl Into<Result<ProcessingState<Shader>>> for Shader {
    fn into(self) -> Result<ProcessingState<Shader>> {
        Ok(ProcessingState::Loaded(self))
    }
}

/// A set of properties used for encoding.
/// Derived from a shader.
#[derive(Debug)]
pub struct EncoderPipeline {
    layout: EncodingLayout,
    entities: BitSet,
    entities_count: usize,
    batch_counts: Vec<usize>,
    batches: Vec<usize>,
    indices: RefCell<Vec<usize>>,
}

impl EncoderPipeline {
    /// Resolve a pipeline from given shader. This effectively does the lookup
    /// of shader metadata generated by the asset pipeline.
    pub fn with_layout(layout: EncodingLayout) -> Self {
        EncoderPipeline {
            layout: layout.clone(),
            entities: BitSet::new(),
            entities_count: 0,
            batch_counts: Vec::with_capacity(32),
            batches: Vec::with_capacity(1024),
            indices: RefCell::new(vec![]),
        }
    }

    /// Retreive the encoding layout
    pub fn layout(&self) -> &EncodingLayout {
        &self.layout
    }

    /// Retreive the combined size in bytes of whole uniform buffer written in the pipeline encoding
    pub fn ubo_size(&self) -> usize {
        (self.layout.padded_size as usize) * self.entities_count
    }

    /// Get BitSet structure that holds associations
    /// of entity IDs to the pipeline.
    pub fn bitset(&self) -> &BitSet {
        &self.entities
    }

    /// Retreive write index vector, which holds the encoding write position
    /// for every entity in the pipeline. Vector is keyed by the iteration index,
    /// not by the entity id.
    pub fn indices(&self) -> Ref<'_, Vec<usize>> {
        if self.indices.borrow().len() == self.batches.len() {
            self.indices.borrow()
        } else {
            let mut batch_indices = Vec::with_capacity(self.batch_counts.len());
            let mut total = 0;
            for count in &self.batch_counts {
                batch_indices.push(total);
                total += *count;
            }

            {
                let indices = &mut self.indices.borrow_mut();
                indices.clear();
                indices.extend(self.batches.iter().map(|&batch| {
                    let idx = batch_indices[batch];
                    batch_indices[batch] = idx + 1;
                    idx
                }));
            }

            self.indices.borrow()
        }
    }

    /// Add entity id to the pipeline.
    #[inline]
    pub fn add_id(&mut self, id: Index, batch: usize) {
        if !self.entities.add(id) {
            if self.batch_counts.len() <= batch {
                self.batch_counts.resize(batch + 1, 0);
            }
            self.batch_counts[batch] += 1;
            self.batches.push(batch);
            self.entities_count += 1;
        }
    }

    /// Remove entity id from the pipeline.
    #[inline]
    pub fn remove_id(&mut self, id: Index) {
        if self.entities.remove(id) {
            let batch = self.batches[id as usize];
            self.batch_counts[batch] -= 1;
            self.batches.remove(id as usize);
            self.entities_count -= 1;
        }
    }

    /// Remove all associated entities from the pipeline.
    pub fn clear(&mut self) {
        self.entities.clear();
        self.batch_counts.clear();
        self.batches.clear();
        self.indices.get_mut().clear();
        self.entities_count = 0;
    }
}
